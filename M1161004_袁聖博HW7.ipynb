{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 總結一下第六章的概念：\n",
        "機器學習的通用工作流程\n",
        "\n",
        "定義任務：了解問題領域和客戶端要求的業務邏輯。收集數據集，了解數據代表什麼，然後選擇衡量任務成功的方式。 \n",
        "\n",
        "開發模型——準備你的數據以便它可以被機器學習模型處理，選擇一個模型評估協議和一個簡單的基線來擊敗，訓練第一個具有泛化能力並且可以過擬合的模型，然後對你的模型進行正則化和調整模型，直到您獲得最佳的泛化性能。 \n",
        "\n",
        "部署模型——向利益相關者展示您的工作，將模型發送到 Web 服務器、移動應用程序、網頁或嵌入式設備，監控模型在野外的性能，並開始收集構建所需的數據下一代模型。"
      ],
      "metadata": {
        "id": "vTVRNx3PeNRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 定義任務： 首先就要把問題框定出來，再來就是收集很多的dataset，收集完後，就是要了解你所收集的數據是什麼，並且要深入了解它。接著，如果我所搜集的dataset有image or NL，這部分直接查看樣本跟labels或比較好；如果是數字特徵，最好繪製一下坐標圖，了解值的範圍跟頻率；假設它包含了位置信息，最好的方式就是繪製成一個地圖；萬一樣本缺少某些feature，就可能需要在準備dataset的時候去處理這部分的問題。 最後就是選擇衡量成功的標準。 \n",
        "\n",
        "* 開發模型： 要開發模型的話，就必須要準備這些東西:\n",
        "\n",
        "  Prepare dataset（包括）： 矢量化\n",
        "\n",
        "  神經網絡中的所有輸入和目標通常必須是浮點數據的張量（或者，在特定情況下，整數或字符串的張量）。無論您需要處理什麼數據（聲音、圖像、文本），您都必須首先將其轉換為張量，這一步驟稱為數據矢量化。例如，在第 4 章的前兩個文本分類示例中，我們從表示為整數列表（代表單詞序列）的文本開始，然後使用 one-hot 編碼將它們轉換為 float32 數據的張量。在數字分類和預測房價的例子中，數據是矢量化的，所以我們可以跳過這一步。 \n",
        "  \n",
        "  標準\n",
        "  \n",
        "  在第 2 章的 MNIST 數字分類示例中，我們從編碼為 0-255 範圍內的整數的圖像數據開始，對灰度值進行編碼。在將這些數據輸入網絡之前，我們必須將其轉換為 float32 並除以 255，這樣我們最終會得到 0-1 範圍內的浮點值。同樣，在預測房價時，我們從具有各種範圍的特徵開始——一些特徵具有較小的浮點值，而另一些具有相當大的整數值。在我們將這些數據輸入到我們的網絡之前，我們必須獨立地對每個特徵進行歸一化，使其標準差為 1，平均值為 0。 一般來說，向神經網絡輸入具有相對較大值的數據（例如，多位整數，其遠大於網絡權重所採用的初始值）或異構數據是不安全的（例如，一個特徵在 0-1 範圍內而另一個特徵在 100-200 範圍內的數據）。\n",
        "  \n",
        "  這樣做會觸發大的梯度更新，從而阻止網絡收斂。為了使網絡更容易學習，數據應具有以下特徵： \n",
        "  \n",
        "    取小值 - 通常，大多數值應在 0–1 範圍內。 \n",
        "  \n",
        "  同質化\n",
        "\n",
        "  所有特徵的取值都應在大致相同的範圍內。 \n",
        "\n",
        "  此外，以下更嚴格的規範化實踐很常見並且可以提供幫助，儘管它並不總是必要的（例如，我們在數字分類示例中沒有這樣做）：\n",
        "\n",
        "\n",
        "    獨立地對每個特徵進行歸一化，使其均值為 0\n",
        "    獨立地對每個特徵進行歸一化，使其標準差為 1\n"
      ],
      "metadata": {
        "id": "7SyjmR72efnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "處理缺失值\n",
        "\n",
        "數據中有時可能會缺少值。例如，在房價示例中，第一個特徵（數據中索引 0 的列）是人均犯罪率。如果此功能不適用於所有樣本怎麼辦？然後，將在訓練或測試數據中缺少值。 可以完全放棄該功能，但不一定必須這樣做。 如果該特徵是分類的，則可以安全地創建一個表示“缺少值”的新類別。該模型將自動學習這對目標意味著什麼。 如果特徵是數字的，請避免輸入像“0”這樣的任意值，因為它可能會在特徵形成的潛在空間中產生不連續性，從而使在其上訓練的模型更難泛化。相反，請考慮將缺失值替換為數據集中特徵的平均值或中值。還可以訓練模型以根據其他特徵的值來預測特徵值。 請注意，如果期望測試數據中缺少分類特徵，但網絡是在沒有任何缺失值的數據上訓練的，那麼網絡將不會學會忽略缺失值！在這種情況下，應該人為地生成缺少條目的訓練樣本：多次複製一些訓練樣本，並丟棄一些認為可能在測試數據中丟失的分類特徵。 "
      ],
      "metadata": {
        "id": "pBHPruZffrxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 選擇評估協議（三種評估協議）： \n",
        "維護一個保留驗證集——當有大量數據時，這是要走的路。\n",
        "\n",
        "進行 K-fold交叉驗證——當樣本太少而無法進行可靠驗證時，這是正確的選擇。 \n",
        "\n",
        "進行迭代 K-fold驗證——這是為了在可用數據很少時執行高度準確的模型評估。 \n",
        "\n",
        "Beat a baseline（三件重要的事情）： \n",
        "\n",
        "開發一個能夠超越簡單baseline的小型模型\n",
        "\n",
        "* 特徵工程\n",
        "  \n",
        "  過濾掉無信息的特徵（特徵選擇）並利用對問題的了解來開發可能有用的new feature。 \n",
        "\n",
        "* 選擇正確的架構先驗——將使用哪種類型的模型架構？\n",
        "\n",
        "  密集連接網絡、卷積神經網絡、循環神經網絡、Transformer？\n",
        "\n",
        "  深度學習甚至是完成任務的好方法，還是應該使用其他方法？ \n",
        "\n",
        "\n",
        "* 選擇一個足夠好的訓練配置\n",
        "\n",
        "  應該使用什麼損失函數？什麼批量大小和學習率？\n",
        "\n",
        "\n",
        "* 選擇正確的損失函數 \n",
        "\n",
        "  通常不可能直接針對衡量問題成功與否的指標進行優化。有時沒有簡單的方法將度量轉化為損失函數；畢竟，損失函數需要在只給定小批量數據的情況下是可計算的（理想情況下，損失函數應該可以計算到一個數據點）並且必須是可微分的（否則，您不能使用反向傳播來計算訓練你的網絡）。例如，廣泛使用的分類度量 ROC AUC 不能直接優化。因此，在分類任務中，通常會針對 ROC AUC 的代理指標進行優化，例如交叉熵。一般來說，可以希望交叉熵越低，ROC AUC 越高。"
      ],
      "metadata": {
        "id": "yYB7NwXSfycU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 開發一個過度擬合的模型： \n",
        "要搞清楚我們自己在做實驗的時候需要多大的模型，就必須要開發一個過度擬合的模型，添加圖層然後使圖層變大，再來就是訓練更多次。性能如果開始下降，我們這個實驗結果就有了過度擬合。 \n",
        "\n",
        "\n",
        "* 正則化和調整模型： \n",
        "花費最多時間在這裡（很多作業都是一樣qwq），不斷地反復訓練模型還有修改，還有評估實驗的數據，就跟自己要花時間看書，或者你打電動也是要花時間打怪練等。\n",
        "\n",
        "如果模型較小的情況下，要添加L1 or L2正則化 \n",
        "部署模型（四個步驟(?）：\n",
        "\n",
        "* 向別人解釋作法跟設定期望 \n",
        "\n",
        "* 發佈推理出來的模型 \n",
        "\n",
        "  在Browser中部署模型 \n",
        "  \n",
        "  在設備上部署模型 \n",
        "\n",
        "* 推理模型並且優化 \n",
        "\n",
        "  監控模型 \n",
        "\n",
        "* 維護模型 \n",
        "\n",
        "      要注意的事情很多 \n"
      ],
      "metadata": {
        "id": "XU4-F-sWgZs4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mOm1s7QfCWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}